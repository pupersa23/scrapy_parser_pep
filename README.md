# Проект парсинга pep
Парсер предназначен для сбора информации о нововведениях Python и
количестве статусов документов PEP

### Используемые технологии:
+ Python
+ Scrapy

### Как запустить проект:

Клонировать репозиторий и перейти в него в командной строке:
```
git clone https://github.com/Ponimon4ik/scrapy_parser_pep
```
```
cd scrapy_parser_pep
```

Cоздать и активировать виртуальное окружение:

```
python3 -m venv env
```
```
source env/bin/activate
```

Установить зависимости из файла requirements.txt:

```
python3 -m pip install --upgrade pip
```
```
pip install -r requirements.txt
```

### Как пользоваться парсером:

Парсер выводит собранную информацию в два файла .csv:
+ В первый файл список всех PEP: номер, название и статус.
+ Второй файл содержит сводку по статусам PEP — сколько найдено документов в каждом статусе (статус, количество)

Что бы запустить парсер необходимо выполнить команду

```
scrapy crawl pep 
```
Команда спарсит документацию PEP посчитает количество PEP в каждом
статусе и сохранит результат сбора информации в папку results

### Автор:
+ Рязанов Владимир - [pupersa23](https://github.com/pupersa23)